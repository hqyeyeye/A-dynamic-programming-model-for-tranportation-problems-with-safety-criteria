# A dynamic programming model for transportation problems with safety criteria
The proposed model aims to bridge the research gap between statistical analysis of driving risk factors and optimization models for improving driver safety by incorporating the latest statistical findings. Our study shows that by using a dynamic model that considers real-time risk indicators from data analysis, drivers can avoid dangerous driving conditions by adjusting their speed and planning rest stops strategically to reduce the risk. The optimal policy generated by our model can effectively manage the driver's timing and risk to guarantee timely arrival with minimal risk. In addition, we present a comparison between the risks associated with autonomous driving and human driving as an illustrative use case.

The significant factors that substantially impact the risk are weather and traffic. In the Markov Decision Process (MDP), we utilized an internal factor related to driver fatigue, denoted as "g" in our code and referred to as driver degradation in our paper. In other words, the driver's performance will change based on the amount of time and conditions of driving, eventually impacting the level of risk. Furthermore, the rest stop could help alleviate driver fatigue to reduce the risk. The main difference between autonomous driving and human driving is the absence of fatigue in autonomous driving. We utilized a constant driver degradation (g_0) in the autonomous driving model.

# To run the human driving model, here are related files:
To execute the code, please run the script located in "run.py".The file "valueiteration.py" contains the code for the value iteration process used to find the optimal policy for our Markov Decision Process (MDP) model. The file includes variables related to the MDP model for human driving, such as state, action, transition function, and others. You can utilize the "valueiteration_write.py" script to monitor and evaluate the fluctuating value of outcomes at different stages by importing "ValueIterationModel". The "state.py" file defines the state variable in the MDP model.

# To run the autonomous driving model, here are related files:
The file "practice.py" provides the code for the value iteration process used to find the optimal policy for our Markov Decision Procedure (MDP) model when driver degradation is constant, denoted as g_c. The file contains variables related to the MDP model, including state, action, and transition functions. To run the file, please execute the code in "run_autonomous.py".




